{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"catedra.jpg\" width=\"400\"/> \n",
    "<div style=\"text-align: right\"></div>\n",
    "\n",
    "<b><center>Facial Recognition</b></center>\n",
    "_<b>Student:</b> Soa Amendaño.__<b>Mail:</b> samendano@est.ups.edu.est.ec._\n",
    "_<b>Student:</b> Christian Dután.__<b>Mail:</b> cdutan@est.ups.edu.est.ec._  \n",
    "_<b>Date:</b> 30 de Julio del 2019._  \n",
    "_<b>Teacher:</b> Vladimir Robles._  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The facial recognition system is a computer-driven application that automatically identifies a person in a digital image. This is possible by analyzing the facial characteristics of the subject extracted from the image or from a keyframe of a video source, and comparing them with a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|               Areas                |                  Specific applications                  | \n",
    "|------------------------------------|----------------------------------------------------------|\n",
    "|Biometrics                          |Driver's License, Law Programs, Immigration, ID, Passports, Voter Registration, Fraud   |\n",
    "|Security of the information\t     |Login, Application Security, Database Security, Information Encryption, Internet Security, Internet Access, Medical Records, Secure Commerce Terminals, ATMs |\n",
    "|Law Enforcement and Surveillance |Advanced Video Surveillance, CCTV Control, Portal Control, Post-event Analysis, Theft, Suspect Tracking, Research |\n",
    "|Smartcards               |Stored Value, User Authentication |\n",
    "|Access control                   |Access to Facilities, Access to Vehicles|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV is a free artificial vision library originally developed by Intel. Since its first alpha version appeared in January 1999, it has been used in countless applications. From security systems with motion detection, to process control applications where object recognition is required. This is because its publication is given under BSD license, which allows it to be used freely for commercial and research purposes with the conditions expressed therein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in methods to perform facial recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENCV has 3 built-in methods to perform facial recognition, and because #Python we can use any of them just by changing a line of code. Here the 3 methods and how to call them:\n",
    "\n",
    "+ EigenFaces – cv2.face.EigenFaceRecognizer_create()\n",
    "+ FisherFaces – cv2.face.FisherFaceRecognizer_create()\n",
    "+ Local Binary Patterns Histograms (LBPH) – cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "Each one highlights different main components, it is a matter of choosing the right one according to the needs of each project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   EigenFaces                |   FisherFaces               |    Local Binary Patterns Histograms (LBPH)               | \n",
    "|-----------------------------|-----------------------------|----------------------------------------------------------|\n",
    "|<img src=\"1.png\" width=\"400\"/><div style=\"text-align: right\"></div>|<img src=\"2.png\" width=\"400\"/><div style=\"text-align: right\"></div>|<img src=\"3.jpg\" width=\"400\"/><div style=\"text-align: right\"></div> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the Tool in windows with jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we will download the whl file that contains opencv\n",
    "\n",
    "Access the web https://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv\n",
    "and download the binaries that are in the file with the .whl extension. When you open the page, different files appear and you will have to choose the most suitable one for your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"3.PNG\" width=\"400\"/> \n",
    "<div style=\"text-align: right\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create an environment in anaconda\n",
    "\n",
    "+ conda create --name OpenCV python=3.4\n",
    "\n",
    "It is important to remember where the file we downloaded in the previous step is. Now we need to access through the command line and install it. Execute the following command\n",
    "\n",
    "+ pip install \"d:\\opencv\\opencv_python-3.2.0+contrib-cp36-cp36m-win_amd64.whl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replaced the path where you downloaded the file. Once you have written press enter. You should see a message informing you that OpenCV 3.2.0 + contrib has been installed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to install OpenCV using the following command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will install OpenCV together with all its Numpy and contrib dependencies are important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will activate the Python Kernel for execution in Jupyter\n",
    "+ pip install ipykernel\n",
    "+ python -m ipykernel install --user --name OpenCV --display-name \"OpenCV\"\n",
    "+ conda activate OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the installation of OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the openCV is working correctly we use the following code, which will indicate if the libraries are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "    \n",
    "# We load the image from the hard disk\n",
    "imagen = cv2.imread(\"logo.png\")\n",
    " \n",
    "cv2.imshow(\"prueba\", imagen)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image will appear in a window. This indicates that OpenCV has been installed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database of Faces the AT&T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the training photos for the model, we will download a small BD of faces so that it has better precision and to which we will add our face or those that interest us. We download the sample database of the Database of Faces of AT&T Laboratories Cambridge from the following website https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html, unzip the folder, inside it we create one more called orl_faces and within that we create a folder with the name of the faces we want to recognize. The route would be something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project folder\\att_faces\\orl_faces\\Christian_Dutan\n",
    "project folder\\att_faces\\orl_faces\\Soa_Amendano\n",
    "project folder\\att_faces\\orl_faces\\Vladimr_Robles\n",
    "project folder\\att_faces\\orl_faces\\Anita_Parra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code looks for a face, takes a picture of it and saves it in the corresponding folder, it will be to learn faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m71\u001b[0m\n\u001b[1;33m    cv2.imshow('OpenCV Entrenamiento de '+nombre, img)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#OpenCV module\n",
    "import cv2\n",
    "#Module to read directories and file paths\n",
    "import os\n",
    "#OpenCV works with numpy fixes\n",
    "import numpy\n",
    "#Get the name of the person we are capturing\n",
    "import sys\n",
    "nombre = input()\n",
    "\n",
    "\n",
    "print('Presione Esc para salir...')\n",
    "\n",
    "#Directory where the folder with the person's name is locateddir_faces = 'att_faces/orl_faces'\n",
    "path = os.path.join(dir_faces, nombre)\n",
    "\n",
    "#Size to reduce photos to thumbnails\n",
    "size = 4\n",
    "\n",
    "#If there is no folder with the name entered then it is createdif not os.path.isdir(path):\n",
    "       os.mkdir(path)\n",
    "\n",
    "#we load the template of initialize the webcam\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "img_width, img_height = 112, 92\n",
    "\n",
    "#Photo cycle\n",
    "count = 0\n",
    "while count < 100:\n",
    "    #we read a frame and save it\n",
    "    rval, img = cap.read()\n",
    "    img = cv2.flip(img, 1, 0)\n",
    "\n",
    "    #we convert the image to black and white\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #resize image\n",
    "    mini = cv2.resize(gray, (int(gray.shape[1] / size), int(gray.shape[0] / size)))\n",
    "\n",
    "    \"\"\"we look for the coordinates of the faces (if any) and\n",
    "    we keep your position\"\"\"\n",
    "    faces = face_cascade.detectMultiScale(mini)    \n",
    "    faces = sorted(faces, key=lambda x: x[3])\n",
    "    \n",
    "    if faces:\n",
    "        face_i = faces[0]\n",
    "        (x, y, w, h) = [v * size for v in face_i]\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        face_resize = cv2.resize(face, (img_width, img_height))\n",
    "        \n",
    "        #We draw a rectangle in the coordinates of the face\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        #We put the name in the rectangle\n",
    "        cv2.putText(img, nombre, (x - 10, y - 10), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))        \n",
    "\n",
    "        #The name of each photo is the cycle number\n",
    "         #We get the name of the photo\n",
    "         #After the last we add 1 to continue with the other names\n",
    "        pin=sorted([int(n[:n.find('.')]) for n in os.listdir(path)\n",
    "               if n[0]!='.' ]+[0])[-1] + 1\n",
    "\n",
    "        #We put the photo in the directory\n",
    "        cv2.imwrite('%s/%s.png' % (path, pin), face_resize)\n",
    "\n",
    "        #Cycle counter\n",
    "        count += 1\n",
    "\n",
    "    #We show the image\n",
    "    cv2.imshow('OpenCV Entrenamiento de '+nombre, img)\n",
    "\n",
    "    #If the ESC key is pressed, the program closes\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Captura.PNG\" width=\"400\"/> \n",
    "<div style=\"text-align: right\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the person's name is the same as the one you put in the name of your folder.\n",
    "\n",
    "By default the script takes 100 photos of the face, but remember that the higher the training, the better results will be obtained.\n",
    "\n",
    "Try that only one person appears in the scene so as not to save other faces with the same label or name.\n",
    "\n",
    "To start detecting and recognizing faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV module\n",
    "import cv2\n",
    "#Module to read directories and file paths\n",
    "import os\n",
    "#OpenCV works with numpy fixes\n",
    "import numpy\n",
    "\n",
    "\n",
    "# Part 1: Creating model training\n",
    "print('Capturando...')\n",
    "print('Presione Esc para salir...')\n",
    "\n",
    "#Directory where folders with training faces are located\n",
    "dir_faces = 'att_faces/orl_faces'\n",
    "\n",
    "#Size to reduce photos to thumbnails\n",
    "size = 4\n",
    "\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images, lables, names, id) = ([], [], {}, 0)\n",
    "for (subdirs, dirs, files) in os.walk(dir_faces):\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(dir_faces, subdir)\n",
    "        for filename in os.listdir(subjectpath):\n",
    "            path = subjectpath + '/' + filename\n",
    "            lable = id\n",
    "            images.append(cv2.imread(path, 0))\n",
    "            lables.append(int(lable))\n",
    "        id += 1\n",
    "(im_width, im_height) = (112, 92)\n",
    "\n",
    "# Create a Numpy array from the previous two lists\n",
    "(images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
    "# OpenCV trains a model from the images\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(images, lables)\n",
    "\n",
    "\n",
    "# Part 2: Use the trained model in operation with the camera\n",
    "face_cascade = cv2.CascadeClassifier( 'haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # let's read a frame and save it\n",
    "    rval, frame = cap.read()\n",
    "    frame=cv2.flip(frame,1,0)\n",
    "\n",
    "    #convert the image to black and white\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # resize the image\n",
    "    mini = cv2.resize(gray, (int(gray.shape[1] / size), int(gray.shape[0] / size)))\n",
    "\n",
    "    \"\"\"we look for the coordinates of the faces (if any) and\n",
    "    we keep your position\"\"\"\n",
    "    faces = face_cascade.detectMultiScale(mini)\n",
    "    \n",
    "    for i in range(len(faces)):\n",
    "        face_i = faces[i]\n",
    "        (x, y, w, h) = [v * size for v in face_i]\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        face_resize = cv2.resize(face, (im_width, im_height))\n",
    "\n",
    "        # Attempted to recognize the face\n",
    "        prediction = model.predict(face_resize)\n",
    "        \n",
    "         #Draw a rectangle in the coordinates of the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        \n",
    "       # Writing the name of the recognized face\n",
    "         # The face variable will have the name of the recognized person\n",
    "        cara = '%s' % (names[prediction[0]])\n",
    "\n",
    "        #If the prediction is less than 100 accurate, it is taken as a valid prediction\n",
    "        if prediction[1]<100 :\n",
    "          # We put the name of the person who was recognized\n",
    "          cv2.putText(frame,'%s - %.0f' % (cara,prediction[1]),(x-10, y-10), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))\n",
    "\n",
    "          #In case the face is of an acquaintance certain actions will be carried out\n",
    "           #Search if the names of recognized people are within those who have access\n",
    "\n",
    "         #If the prediction is greater than 100 it is not a recognition with sufficient accuracy\n",
    "        elif prediction[1]>101 and prediction[1]<500:           \n",
    "            #If the face is unknown, put unknown\n",
    "            cv2.putText(frame, 'Desconocido',(x-10, y-10), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))  \n",
    "\n",
    "        #We show the image\n",
    "        cv2.imshow('OpenCV Reconocimiento facial', frame)\n",
    "\n",
    "    #If the ESC key is pressed the program closes\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5.PNG\" width=\"400\"/> \n",
    "<div style=\"text-align: right\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "OpenCV",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
